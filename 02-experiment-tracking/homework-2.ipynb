{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808a4009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f54d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\r\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\r\n",
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\r\n",
      "  from pandas.core import (\r\n"
     ]
    }
   ],
   "source": [
    "!python3 preprocess_data.py --raw_data_path ./data --dest_path ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e53cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import click\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--data_path\",\n",
    "    default=\"./output\",\n",
    "    help=\"Location where the processed NYC taxi trip data was saved\"\n",
    ")\n",
    "def run_train(data_path: str):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "    rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c33d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import mlflow\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"RF-train\")##\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--data_path\",\n",
    "    default=\"./output\",\n",
    "    help=\"Location where the processed NYC taxi trip data was saved\"\n",
    ")\n",
    "\n",
    "def run_train(data_path: str):\n",
    "    mlflow.sklearn.autolog(log_datasets=False)##\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        print(run.info.run_id)##\n",
    "\n",
    "        rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)##\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e065c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e2c2a2f3cb8542ebb3c5737e32622f95'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['python3', 'train.py'], capture_output=True, text=True)\n",
    "\n",
    "run_id = result.stdout.strip()\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9409561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "run_data = mlflow.get_run(run_id).data\n",
    "run_data.params.get('min_samples_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c6c35df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: 'mlflow ui --backend-store-uri sqlite:///mlfl...>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "[2024-05-27 17:46:02 +0000] [78843] [INFO] Starting gunicorn 22.0.0\n",
      "[2024-05-27 17:46:02 +0000] [78843] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2024-05-27 17:46:02 +0000] [78843] [ERROR] Retrying in 1 second.\n",
      "[2024-05-27 17:46:03 +0000] [78843] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2024-05-27 17:46:03 +0000] [78843] [ERROR] Retrying in 1 second.\n",
      "[2024-05-27 17:46:04 +0000] [78843] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2024-05-27 17:46:04 +0000] [78843] [ERROR] Retrying in 1 second.\n",
      "[2024-05-27 17:46:05 +0000] [78843] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2024-05-27 17:46:05 +0000] [78843] [ERROR] Retrying in 1 second.\n",
      "[2024-05-27 17:46:06 +0000] [78843] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2024-05-27 17:46:06 +0000] [78843] [ERROR] Retrying in 1 second.\n",
      "[2024-05-27 17:46:07 +0000] [78843] [ERROR] Can't connect to ('127.0.0.1', 5000)\n",
      "Running the mlflow server failed. Please see the logs above for details.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.Popen(\"mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e32b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hpo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hpo.py\n",
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--data_path\",\n",
    "    default=\"./output\",\n",
    "    help=\"Location where the processed NYC taxi trip data was saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--num_trials\",\n",
    "    default=15,\n",
    "    help=\"The number of parameter evaluations for the optimizer to explore\"\n",
    ")\n",
    "\n",
    "\n",
    "def run_optimization(data_path: str, num_trials: int):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "    def objective(params):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_val)\n",
    "\n",
    "            rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(42)  # for reproducible results\n",
    "    fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10fcba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "2024/05/27 17:58:07 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-hyperopt' does not exist. Creating a new experiment.\n",
      "100%|██████████| 15/15 [00:57<00:00,  3.83s/trial, best loss: 5.335419588556921]\n"
     ]
    }
   ],
   "source": [
    "!python3 hpo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93d85fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model.py\n",
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import mlflow\n",
    "\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "EXPERIMENT_NAME = \"random-forest-best-models\"\n",
    "RF_PARAMS = ['max_depth', 'n_estimators', 'min_samples_split', 'min_samples_leaf', 'random_state']\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def train_and_log_model(data_path, params):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        for param in RF_PARAMS:\n",
    "            params[param] = int(params[param])\n",
    "\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model on the validation and test sets\n",
    "        val_rmse = mean_squared_error(y_val, rf.predict(X_val), squared=False)\n",
    "        mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--data_path\",\n",
    "    default=\"./output\",\n",
    "    help=\"Location where the processed NYC taxi trip data was saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--top_n\",\n",
    "    default=5,\n",
    "    type=int,\n",
    "    help=\"Number of top models that need to be evaluated to decide which one to promote\"\n",
    ")\n",
    "\n",
    "\n",
    "def run_register_model(data_path: str, top_n: int):\n",
    "\n",
    "    client = MlflowClient(\"http://127.0.0.1:5000\")\n",
    "\n",
    "    # Retrieve the top_n model runs and log the models\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=top_n,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "\n",
    "    for run in runs:\n",
    "        train_and_log_model(data_path=data_path, params=run.data.params)\n",
    "\n",
    "    # Select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=top_n,\n",
    "        order_by=[\"metrics.test_rmse ASC\"]\n",
    "    )[0]\n",
    "\n",
    "    print(best_run.info.run_id)\n",
    "\n",
    "    # Register the best model\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "        name=\"random-forest-model\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_register_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3f9b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a345f070a9064af0bd3031febe828147'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['python3', 'register_model.py'], capture_output=True, text=True)\n",
    "\n",
    "run_id = result.stdout.strip()\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8f69c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.567408012462019"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient(\"http://127.0.0.1:5000\")\n",
    "run_data = client.get_run(run_id).data\n",
    "run_data.metrics.get('test_rmse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
